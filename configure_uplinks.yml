---
- name: Configure uplinks from ESXi host
  hosts: "{{ apic }}"
  connection: local
  gather_facts: no
  vars_files:
    - ./vars/configure_uplinks_vars.yml
    - ./credentials/aci_credentials.yml
  vars:
    leaf_switches: []
    vmkernel_apps: []
    selected_ports_201:
      - switch: 201
        port: 1
      - switch: 201
        port: 3
    selected_ports_202:
      - switch: 202
        port: 17
      - switch: 202
        port: 18

  tasks:


#### 1) Get the available leaf switch pairs ####
      #endpoint: https://{{ inventory_hostname }}/api/node/mo/uni/infra.json?query-target=subtree&target-subtree-class=infraAccPortP&query-target-filter=not(wcard(polUni.dn, "__ui_"))&target-subtree-class=infraAccPortP&query-target=subtree
    - name: Query for all leaf switches
      aci_rest:
        host: "{{ inventory_hostname }}"
        username: "{{ aci_username }}"
        password: "{{ aci_password }}"
        method: get
        path: /api/node/mo/uni/infra.json?query-target=subtree&target-subtree-class=infraAccPortP&query-target-filter=not(wcard(polUni.dn, "__ui_"))&target-subtree-class=infraAccPortP&query-target=subtree
        output_level: debug
        validate_certs: no
      register: leaf_switches_result

    # - name: Print leaf switch nodes
    #   debug:
    #     var: leaf_switches_result

    #The leaf_switches variable indicates what leaf switches are in the topology
    - name: Set Leaf Switches fact
      set_fact:
        leaf_switches: "{{ leaf_switches }} + [ '{{ item | regex_replace('[^0-9]+', '') }}' ]"
      loop: "{{leaf_switches_result | json_query('imdata[*].infraAccPortP.attributes.name') }}"

    # - name: Print Leaf Switches fact
    #   debug:
    #     var: leaf_switches


#### 2) Get a list of open ports on the switch pairs ####
    - name: Delete any existing open port variable file
      file:
        path: "{{ playbook_dir }}/vars/open_ports.yml"
        state: absent

      #endpoint: https://{{ inventory_hostname }}/api/node/class/infraHPortS.json?query-target-filter=and(wcard(infraHPortS.dn,"202"),eq(infraPortBlk.descr, "open"))&query-target=subtree&rsp-subtree=children&target-subtree-class=infraPortBlk
      #NOTE: For each switch, this task appends the open port objects to leaf_interface_profile_result
    - name: Query for all open ports
      aci_rest:
        host: "{{ inventory_hostname }}"
        username: "{{ aci_username }}"
        password: "{{ aci_password }}"
        path: "/api/node/class/infraHPortS.json?query-target-filter=and(wcard(infraHPortS.dn, \"{{ item | regex_replace('[^0-9]+', '') }}\"),eq(infraPortBlk.descr, \"open\"))&query-target=subtree&rsp-subtree=children&target-subtree-class=infraPortBlk"
        method: get
        output_level: debug
        validate_certs: no
      register: leaf_interface_profile_result
      loop: "{{leaf_switches_result | json_query('imdata[*].infraAccPortP.attributes.name') }}"


    # - name: Print Leaf Interface Result
    #   debug:
    #     var: leaf_interface_profile_result

    - name: Copy leaf interface profile results to file
      copy:
        content: "{{ leaf_interface_profile_result | to_nice_json }}"
        dest: open_ports.txt

    - name: Convert open_ports.txt file to list variable
      shell: "cat ./open_ports.txt"
      register: port_file_lines

    - name: Populate open_ports.yml variable file from template
      template:
        src: ./templates/open_ports.j2
        dest: ./vars/open_ports.yml

    - name: Remove extraneous switch text
      replace:
        regexp: 'prof-'
        replace: ''
        backup: no
        path: ./vars/open_ports.yml

    - name: Remove extraneous port text
      replace:
        regexp: '-IfSel'
        replace: ''
        backup: no
        path: ./vars/open_ports.yml

    - name: Include open_ports variable for processing
      include_vars:
        file: ./vars/open_ports.yml

    - name: confirm open_ports variable
      debug:
        var: open_ports

    - name: Delete open_ports.txt as it is no longer needed
      file:
        path: ./open_ports.txt
        state: absent

#### 3) User must choose switch pair and interfaces to configure ####
#TODO: In production, the open_ports variable will be made available in SNOW.
#For this POC, we will simply choose the first available ports from the variable file
    # - name: Delete any existing selected port variable file
    #   file:
    #     path: "{{ playbook_dir }}/vars/selected_ports_{{ item }}.yml"
    #     state: absent
    #   loop: "{{ leaf_switches }}"

    # - name: Choose first two available ports from each switch in the pair
    #   template:
    #     src: ./templates/selected_ports.j2
    #     dest: "./vars/selected_ports_{{ item }}.yml"
    #   loop: "{{ leaf_switches }}"

    # - name: Include selected_ports variable for processing
    #   include_vars:
    #     file: "{{ playbook_dir }}/vars/selected_ports_{{ item }}.yml"
    #   loop: "{{ leaf_switches }}"
    #   delegate_to: localhost

    #NOTE: Strictly here to show we got the values we wanted
    - name: confirm selected_ports variable
      debug:
        var: 'selected_ports_{{ item }}'
      loop: "{{ leaf_switches }}"

#### 4) User must choose the use-case ####
#NOTE: In production, the use_case variable will be selected by the operator in SNOW.
#For this POC, we will simply populate the use_case variable with a survey
#The default value in the survey is use_case: vmkernel_bundled


#### 5.) User must provide the server name -->  {{server_name}}  ( convert to title-case ) ####
#NOTE: In production, the server variable will be selected by the operator in SNOW.
#For this POC, we will simply populate the server_name variable with a survey
#The default value in the survey is server_name: test_server

#### 6.) If 4.a or 4.b == true Need to get the 3 trunked vlans by having the user choose a ####
#### VMKernel Application to assign the server to ####

    - block:
      #endpoint: https://{{ inventory_hostname }}/api/node/class/fvAp.json?query-target-filter=and(wcard(fvAp.name,\"VMKernel\"))
      - name: Query for all VMKernel Applications
        aci_rest:
          host: "{{ inventory_hostname }}"
          username: "{{ aci_username }}"
          password: "{{ aci_password }}"
          path: "/api/node/class/fvAp.json?query-target-filter=and(wcard(fvAp.name,\"VMKernel\"))"
          method: get
          output_level: debug
          validate_certs: no
        register: vmkernel_app_result

      # - name: Print all VMKernel Applications
      #   debug:
      #     msg: "{{ item }}"
      #   loop: "{{vmkernel_app_result | json_query('imdata[*].fvAp.attributes.name') }}"

      #The leaf_switches variable indicates what leaf switches are in the topology
      - name: Set vmkernel_apps fact
        set_fact:
          vmkernel_apps: "{{ vmkernel_apps }} + [ '{{ item}}' ]"
        loop: "{{vmkernel_app_result | json_query('imdata[*].fvAp.attributes.name') }}"

      - name: Confirm vmkernel_apps
        debug:
          var: vmkernel_apps

      #NOTE: In production, the ap_name variable will be selected by the operator in SNOW.
      #For this POC, we will simply populate the ap_name with the first available app
      - name: Set the selection of the VMKernel app
        set_fact:
          ap_name: "{{ vmkernel_apps[0] }}"


      - name: Obtain Management VLAN ID for "{{ ap_name }}"
        aci_rest:
          host: "{{ inventory_hostname }}"
          username: "{{ aci_username }}"
          password: "{{ aci_password }}"
          path: "/api/node/class/fvAEPg.json?query-target-filter=and(wcard(fvAEPg.name,\"Management\"),wcard(fvAEPg.dn,\"{{ap_name}}\"))&rsp-subtree=full"
          method: get
          output_level: debug
          validate_certs: no
        register: mgmt_result

      - name: Confirm mgmt_result
        debug:
          var: mgmt_result

      - name: Obtain Vmotion VLAN ID for "{{ ap_name }}"
        aci_rest:
          host: "{{ inventory_hostname }}"
          username: "{{ aci_username }}"
          password: "{{ aci_password }}"
          path: "/api/node/class/fvAEPg.json?query-target-filter=and(wcard(fvAEPg.name,\"Vmotion\"),wcard(fvAEPg.dn,\"{{ap_name}}\"))&rsp-subtree=full"
          method: get
          output_level: debug
          validate_certs: no
        register: vmotion_result

      - name: Confirm mgmt_result
        debug:
          var: vmotion_result

      - name: Obtain VSan VLAN ID for "{{ ap_name }}"
        aci_rest:
          host: "{{ inventory_hostname }}"
          username: "{{ aci_username }}"
          password: "{{ aci_password }}"
          path: "/api/node/class/fvAEPg.json?query-target-filter=and(wcard(fvAEPg.name,\"Vsan\"),wcard(fvAEPg.dn,\"{{ap_name}}\"))&rsp-subtree=full"
          method: get
          output_level: debug
          validate_certs: no
        register: vsan_result

      - name: Confirm mgmt_result
        debug:
          var: vsan_result

      when: use_case == "vmkernel_bundled" or use_case == "vmkernel_unbundled"


#### 7.) If use-case is a port-channel bundle then create the appropriate virtual-port-channel policy-group ####

#### 7.1.) If 4.b (VmKernel port - trunked, bundled) == true, Create new virtual-port-channel policy-group for the management vlans ####

    - block:

      # In the GUI, this creates a new PC/VPC Interface Policy Group under
      # Fabric->Access Policies->Interfaces->Leaf Interfaces->Policy Groups->PC Interface
      - name: Create new virtual-port-channel policy-group for the management vlans
        aci_rest:
          host: "{{ inventory_hostname }}"
          username: "{{ aci_username }}"
          password: "{{ aci_password }}"
          path: "/api/node/mo/uni/infra/funcprof/accbundle-Vpc-{{ server_name }}-VpcPolGrp.json"
          method: post
          output_level: debug
          validate_certs: no
          src: ./vars/vpc_policy_group.json
        register: policy_group_result

      - name: Confirm policy_group_result
        debug:
          var: policy_group_result

      when: use_case == "vmkernel_bundled"

#### 7.2) If 4.d (VmGuest ports - bundled) == true, Create new virtual-port-channel policy-group for the VM Guests ####

    - block:

      # In the GUI, this creates a new PC/VPC Interface Policy Group under
      # Fabric->Access Policies->Interfaces->Leaf Interfaces->Policy Groups->PC Interface
      - name: Create new virtual-port-channel policy-group for the VM Guests
        aci_rest:
          host: "{{ inventory_hostname }}"
          username: "{{ aci_username }}"
          password: "{{ aci_password }}"
          path: "/api/node/mo/uni/infra/funcprof/accbundle-Vpc-{{server_name}}Guests-VpcPolGrp.json"
          method: post
          output_level: debug
          validate_certs: no
          src: ./vars/vpc_policy_group.json
        register: policy_group_result

      - name: Confirm policy_group_result
        debug:
          var: policy_group_result

      when: use_case == "vmguest_bundled"

# {{apic}}/node/class/infraHPortS.json?query-target-filter=and(wcard(infraHPortS.dn,"{{node_id}}"),eq(infraPortBlk.descr, "open"))&query-target=subtree&rsp-subtree=children&target-subtree-class=infraPortBlk
